{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63591716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.csv as csv\n",
    "# Omit the header row (include_header=True is the default)\n",
    "options = csv.WriteOptions(include_header=False)\n",
    "csv.write_csv(table, \"data.csv\", options)\n",
    "\n",
    "file = csv.read_csv('../lm-vol/LANL_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0333370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function read_csv in module pyarrow._csv:\n",
      "\n",
      "read_csv(...)\n",
      "    read_csv(input_file, read_options=None, parse_options=None, convert_options=None, MemoryPool memory_pool=None)\n",
      "    \n",
      "    Read a Table from a stream of CSV data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    input_file : string, path or file-like object\n",
      "        The location of CSV data.  If a string or path, and if it ends\n",
      "        with a recognized compressed file extension (e.g. \".gz\" or \".bz2\"),\n",
      "        the data is automatically decompressed when reading.\n",
      "    read_options : pyarrow.csv.ReadOptions, optional\n",
      "        Options for the CSV reader (see pyarrow.csv.ReadOptions constructor\n",
      "        for defaults)\n",
      "    parse_options : pyarrow.csv.ParseOptions, optional\n",
      "        Options for the CSV parser\n",
      "        (see pyarrow.csv.ParseOptions constructor for defaults)\n",
      "    convert_options : pyarrow.csv.ConvertOptions, optional\n",
      "        Options for converting CSV data\n",
      "        (see pyarrow.csv.ConvertOptions constructor for defaults)\n",
      "    memory_pool : MemoryPool, optional\n",
      "        Pool to allocate Table memory from\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`pyarrow.Table`\n",
      "        Contents of the CSV file as a in-memory table.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Defining an example file from bytes object:\n",
      "    \n",
      "    >>> import io\n",
      "    >>> s = \"animals,n_legs,entry\\nFlamingo,2,2022-03-01\\nHorse,4,2022-03-02\\nBrittle stars,5,2022-03-03\\nCentipede,100,2022-03-04\"\n",
      "    >>> print(s)\n",
      "    animals,n_legs,entry\n",
      "    Flamingo,2,2022-03-01\n",
      "    Horse,4,2022-03-02\n",
      "    Brittle stars,5,2022-03-03\n",
      "    Centipede,100,2022-03-04\n",
      "    >>> source = io.BytesIO(s.encode())\n",
      "    \n",
      "    Reading from the file\n",
      "    \n",
      "    >>> from pyarrow import csv\n",
      "    >>> csv.read_csv(source)\n",
      "    pyarrow.Table\n",
      "    animals: string\n",
      "    n_legs: int64\n",
      "    entry: date32[day]\n",
      "    ----\n",
      "    animals: [[\"Flamingo\",\"Horse\",\"Brittle stars\",\"Centipede\"]]\n",
      "    n_legs: [[2,4,5,100]]\n",
      "    entry: [[2022-03-01,2022-03-02,2022-03-03,2022-03-04]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "help(csv.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca7fe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__dataframe__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_column',\n",
       " '_ensure_integer_index',\n",
       " '_to_pandas',\n",
       " 'add_column',\n",
       " 'append_column',\n",
       " 'cast',\n",
       " 'column',\n",
       " 'column_names',\n",
       " 'columns',\n",
       " 'combine_chunks',\n",
       " 'drop',\n",
       " 'drop_null',\n",
       " 'equals',\n",
       " 'field',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'from_arrays',\n",
       " 'from_batches',\n",
       " 'from_pandas',\n",
       " 'from_pydict',\n",
       " 'from_pylist',\n",
       " 'get_total_buffer_size',\n",
       " 'group_by',\n",
       " 'itercolumns',\n",
       " 'join',\n",
       " 'nbytes',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'remove_column',\n",
       " 'rename_columns',\n",
       " 'replace_schema_metadata',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'set_column',\n",
       " 'shape',\n",
       " 'slice',\n",
       " 'sort_by',\n",
       " 'take',\n",
       " 'to_batches',\n",
       " 'to_pandas',\n",
       " 'to_pydict',\n",
       " 'to_pylist',\n",
       " 'to_reader',\n",
       " 'to_string',\n",
       " 'unify_dictionaries',\n",
       " 'validate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb120855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319239959, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4fbb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function to_pandas:\n",
      "\n",
      "to_pandas(...) method of pyarrow.lib.Table instance\n",
      "    _PandasConvertible.to_pandas(self, memory_pool=None, categories=None, bool strings_to_categorical=False, bool zero_copy_only=False, bool integer_object_nulls=False, bool date_as_object=True, bool timestamp_as_object=False, bool use_threads=True, bool deduplicate_objects=True, bool ignore_metadata=False, bool safe=True, bool split_blocks=False, bool self_destruct=False, types_mapper=None)\n",
      "    \n",
      "    Convert to a pandas-compatible NumPy array or DataFrame, as appropriate\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    memory_pool : MemoryPool, default None\n",
      "        Arrow MemoryPool to use for allocations. Uses the default memory\n",
      "        pool is not passed.\n",
      "    categories : list, default empty\n",
      "        List of fields that should be returned as pandas.Categorical. Only\n",
      "        applies to table-like data structures.\n",
      "    strings_to_categorical : bool, default False\n",
      "        Encode string (UTF8) and binary types to pandas.Categorical.\n",
      "    zero_copy_only : bool, default False\n",
      "        Raise an ArrowException if this function call would require copying\n",
      "        the underlying data.\n",
      "    integer_object_nulls : bool, default False\n",
      "        Cast integers with nulls to objects\n",
      "    date_as_object : bool, default True\n",
      "        Cast dates to objects. If False, convert to datetime64[ns] dtype.\n",
      "    timestamp_as_object : bool, default False\n",
      "        Cast non-nanosecond timestamps (np.datetime64) to objects. This is\n",
      "        useful if you have timestamps that don't fit in the normal date\n",
      "        range of nanosecond timestamps (1678 CE-2262 CE).\n",
      "        If False, all timestamps are converted to datetime64[ns] dtype.\n",
      "    use_threads : bool, default True\n",
      "        Whether to parallelize the conversion using multiple threads.\n",
      "    deduplicate_objects : bool, default False\n",
      "        Do not create multiple copies Python objects when created, to save\n",
      "        on memory use. Conversion will be slower.\n",
      "    ignore_metadata : bool, default False\n",
      "        If True, do not use the 'pandas' metadata to reconstruct the\n",
      "        DataFrame index, if present\n",
      "    safe : bool, default True\n",
      "        For certain data types, a cast is needed in order to store the\n",
      "        data in a pandas DataFrame or Series (e.g. timestamps are always\n",
      "        stored as nanoseconds in pandas). This option controls whether it\n",
      "        is a safe cast or not.\n",
      "    split_blocks : bool, default False\n",
      "        If True, generate one internal \"block\" for each column when\n",
      "        creating a pandas.DataFrame from a RecordBatch or Table. While this\n",
      "        can temporarily reduce memory note that various pandas operations\n",
      "        can trigger \"consolidation\" which may balloon memory use.\n",
      "    self_destruct : bool, default False\n",
      "        EXPERIMENTAL: If True, attempt to deallocate the originating Arrow\n",
      "        memory while converting the Arrow object to pandas. If you use the\n",
      "        object after calling to_pandas with this option it will crash your\n",
      "        program.\n",
      "    \n",
      "        Note that you may not see always memory usage improvements. For\n",
      "        example, if multiple columns share an underlying allocation,\n",
      "        memory can't be freed until all columns are converted.\n",
      "    types_mapper : function, default None\n",
      "        A function mapping a pyarrow DataType to a pandas ExtensionDtype.\n",
      "        This can be used to override the default pandas type for conversion\n",
      "        of built-in pyarrow types or in absence of pandas_metadata in the\n",
      "        Table schema. The function receives a pyarrow DataType and is\n",
      "        expected to return a pandas ExtensionDtype or ``None`` if the\n",
      "        default conversion should be used for that type. If you have\n",
      "        a dictionary mapping, you can pass ``dict.get`` as function.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    pandas.Series or pandas.DataFrame depending on type of object\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pyarrow as pa\n",
      "    >>> import pandas as pd\n",
      "    \n",
      "    Convert a Table to pandas DataFrame:\n",
      "    \n",
      "    >>> table = pa.table([\n",
      "    ...    pa.array([2, 4, 5, 100]),\n",
      "    ...    pa.array([\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"])\n",
      "    ...    ], names=['n_legs', 'animals'])\n",
      "    >>> table.to_pandas()\n",
      "       n_legs        animals\n",
      "    0       2       Flamingo\n",
      "    1       4          Horse\n",
      "    2       5  Brittle stars\n",
      "    3     100      Centipede\n",
      "    >>> isinstance(table.to_pandas(), pd.DataFrame)\n",
      "    True\n",
      "    \n",
      "    Convert a RecordBatch to pandas DataFrame:\n",
      "    \n",
      "    >>> import pyarrow as pa\n",
      "    >>> n_legs = pa.array([2, 4, 5, 100])\n",
      "    >>> animals = pa.array([\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"])\n",
      "    >>> batch = pa.record_batch([n_legs, animals],\n",
      "    ...                         names=[\"n_legs\", \"animals\"])\n",
      "    >>> batch\n",
      "    pyarrow.RecordBatch\n",
      "    n_legs: int64\n",
      "    animals: string\n",
      "    >>> batch.to_pandas()\n",
      "       n_legs        animals\n",
      "    0       2       Flamingo\n",
      "    1       4          Horse\n",
      "    2       5  Brittle stars\n",
      "    3     100      Centipede\n",
      "    >>> isinstance(batch.to_pandas(), pd.DataFrame)\n",
      "    True\n",
      "    \n",
      "    Convert a Chunked Array to pandas Series:\n",
      "    \n",
      "    >>> import pyarrow as pa\n",
      "    >>> n_legs = pa.chunked_array([[2, 2, 4], [4, 5, 100]])\n",
      "    >>> n_legs.to_pandas()\n",
      "    0      2\n",
      "    1      2\n",
      "    2      4\n",
      "    3      4\n",
      "    4      5\n",
      "    5    100\n",
      "    dtype: int64\n",
      "    >>> isinstance(n_legs.to_pandas(), pd.Series)\n",
      "    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file.to_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da454d05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found non-unique column index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pandas_file \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyarrow/array.pxi:830\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyarrow/table.pxi:3990\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py:819\u001b[0m, in \u001b[0;36mtable_to_blockmanager\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    816\u001b[0m     ext_columns_dtypes \u001b[38;5;241m=\u001b[39m _get_extension_dtypes(table, [], types_mapper)\n\u001b[1;32m    818\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[0;32m--> 819\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_column_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m blocks \u001b[38;5;241m=\u001b[39m _table_to_blocks(options, table, categories, ext_columns_dtypes)\n\u001b[1;32m    822\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py:938\u001b[0m, in \u001b[0;36m_deserialize_column_index\u001b[0;34m(block_table, all_columns, column_indexes)\u001b[0m\n\u001b[1;32m    935\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _reconstruct_columns_from_metadata(columns, column_indexes)\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# ARROW-1751: flatten a single level column MultiIndex for pandas 0.21.0\u001b[39;00m\n\u001b[0;32m--> 938\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[43m_flatten_single_level_multiindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m columns\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py:1185\u001b[0m, in \u001b[0;36m_flatten_single_level_multiindex\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;66;03m# Cheaply check that we do not somehow have duplicate column names\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m index\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m-> 1185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound non-unique column index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mIndex(\n\u001b[1;32m   1188\u001b[0m         [levels[_label] \u001b[38;5;28;01mif\u001b[39;00m _label \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _label \u001b[38;5;129;01min\u001b[39;00m labels],\n\u001b[1;32m   1189\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1190\u001b[0m         name\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1191\u001b[0m     )\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "\u001b[0;31mValueError\u001b[0m: Found non-unique column index"
     ]
    }
   ],
   "source": [
    "pandas_file = file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d632bb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'ANONYMOUS LOGON@C586',\n",
       " 'ANONYMOUS LOGON@C586',\n",
       " 'C1250',\n",
       " 'C586',\n",
       " 'NTLM',\n",
       " 'Network',\n",
       " 'LogOn',\n",
       " 'Success',\n",
       " '1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f5af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.column_names[0] = 'TIME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "500cdf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'ANONYMOUS LOGON@C586',\n",
       " 'ANONYMOUS LOGON@C586',\n",
       " 'C1250',\n",
       " 'C586',\n",
       " 'NTLM',\n",
       " 'Network',\n",
       " 'LogOn',\n",
       " 'Success',\n",
       " '1']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b7eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "1: int64\n",
      "ANONYMOUS LOGON@C586: string\n",
      "ANONYMOUS LOGON@C586: string\n",
      "C1250: string\n",
      "C586: string\n",
      "NTLM: string\n",
      "Network: string\n",
      "LogOn: string\n",
      "Success: string\n",
      "1: int64\n",
      "----\n",
      "1: [[1,1,1,1,1,...,158,158,158,158,158],[158,158,158,158,158,...,305,305,305,305,305],...,[2505441,2505441,2505441,2505441,2505441,...,2505523,2505523,2505523,2505523,2505523],[2505523,2505523,2505523,2505523,2505523,...,2505600,2505600,2505600,2505600,2505600]]\n",
      "ANONYMOUS LOGON@C586: [[\"ANONYMOUS LOGON@C586\",\"C101$@DOM1\",\"C1020$@DOM1\",\"C1021$@DOM1\",\"C1035$@DOM1\",...,\"C749$@DOM1\",\"C749$@DOM1\",\"C954$@DOM1\",\"U113@DOM1\",\"U113@DOM1\"],[\"U1256@DOM1\",\"U1256@DOM1\",\"U194@DOM1\",\"U194@DOM1\",\"U210@DOM1\",...,\"C567$@DOM1\",\"C567$@DOM1\",\"C567$@DOM1\",\"C573$@DOM1\",\"C585$@DOM1\"],...,[\"U5306@DOM1\",\"U5405@DOM1\",\"U5405@DOM1\",\"U5432@DOM1\",\"U5521@DOM1\",...,\"C15236$@DOM1\",\"C1524$@DOM1\",\"C15414$@DOM1\",\"C16166$@DOM1\",\"C16318$@DOM1\"],[\"C16348$@DOM1\",\"C16348$@DOM1\",\"C16348$@DOM1\",\"C16348$@DOM1\",\"C16358$@DOM1\",...,\"U9596@DOM1\",\"U9596@DOM1\",\"U95@DOM1\",\"U9927@DOM1\",\"U9927@DOM1\"]]\n",
      "ANONYMOUS LOGON@C586: [[\"ANONYMOUS LOGON@C586\",\"C101$@DOM1\",\"SYSTEM@C1020\",\"C1021$@DOM1\",\"C1035$@DOM1\",...,\"C749$@DOM1\",\"C749$@DOM1\",\"C954$@DOM1\",\"U113@DOM1\",\"U53@DOM1\"],[\"U1256@DOM1\",\"U1256@DOM1\",\"U194@DOM1\",\"U194@DOM1\",\"U210@DOM1\",...,\"C567$@DOM1\",\"C567$@DOM1\",\"C567$@DOM1\",\"C573$@DOM1\",\"C585$@DOM1\"],...,[\"U5306@DOM1\",\"U5405@DOM1\",\"U5405@DOM1\",\"U5432@DOM1\",\"U5521@DOM1\",...,\"C15236$@DOM1\",\"C1524$@DOM1\",\"C15414$@DOM1\",\"C16166$@DOM1\",\"C16318$@DOM1\"],[\"C16348$@DOM1\",\"C16348$@DOM1\",\"C16348$@DOM1\",\"C16348$@DOM1\",\"C16358$@DOM1\",...,\"U9596@DOM1\",\"U9596@DOM1\",\"U95@DOM1\",\"U9927@DOM1\",\"U9927@DOM1\"]]\n",
      "C1250: [[\"C586\",\"C988\",\"C1020\",\"C1021\",\"C1035\",...,\"C749\",\"C749\",\"C528\",\"C1710\",\"C1710\"],[\"C2029\",\"C586\",\"C5527\",\"C625\",\"C1790\",...,\"C574\",\"C574\",\"C574\",\"C573\",\"C585\"],...,[\"C625\",\"C1619\",\"C1619\",\"C612\",\"C12562\",...,\"C529\",\"C1524\",\"C15414\",\"C16166\",\"C586\"],[\"C16348\",\"C16348\",\"C16348\",\"C1798\",\"C16358\",...,\"C527\",\"C527\",\"C2766\",\"C20919\",\"C20919\"]]\n",
      "C586: [[\"C586\",\"C988\",\"C1020\",\"C625\",\"C586\",...,\"C2106\",\"C749\",\"C528\",\"C1710\",\"C1710\"],[\"C586\",\"C586\",\"C625\",\"C625\",\"C528\",...,\"C467\",\"C553\",\"C988\",\"C2106\",\"C586\"],...,[\"C625\",\"C1619\",\"C599\",\"C612\",\"C612\",...,\"C529\",\"C529\",\"C625\",\"C1065\",\"C586\"],[\"C16348\",\"C457\",\"C625\",\"C16348\",\"C467\",...,\"C123\",\"C527\",\"C1819\",\"C20919\",\"C2327\"]]\n",
      "NTLM: [[\"?\",\"?\",\"Negotiate\",\"Kerberos\",\"Kerberos\",...,\"Kerberos\",\"?\",\"?\",\"?\",\"?\"],[\"Kerberos\",\"?\",\"Kerberos\",\"?\",\"Kerberos\",...,\"Kerberos\",\"Kerberos\",\"Kerberos\",\"Kerberos\",\"Kerberos\"],...,[\"?\",\"?\",\"?\",\"?\",\"Kerberos\",...,\"?\",\"Kerberos\",\"Kerberos\",\"Kerberos\",\"?\"],[\"?\",\"Kerberos\",\"Kerberos\",\"Kerberos\",\"Kerberos\",...,\"?\",\"?\",\"Kerberos\",\"?\",\"?\"]]\n",
      "Network: [[\"Network\",\"Network\",\"Service\",\"Network\",\"Network\",...,\"Network\",\"?\",\"Network\",\"Interactive\",\"?\"],[\"Network\",\"Network\",\"Network\",\"Network\",\"Network\",...,\"Network\",\"Network\",\"Network\",\"Network\",\"Network\"],...,[\"Network\",\"?\",\"?\",\"Network\",\"Network\",...,\"Network\",\"Network\",\"Network\",\"Network\",\"Network\"],[\"Network\",\"Network\",\"Network\",\"Network\",\"Network\",...,\"?\",\"?\",\"Network\",\"?\",\"?\"]]\n",
      "LogOn: [[\"LogOff\",\"LogOff\",\"LogOn\",\"LogOn\",\"LogOn\",...,\"LogOn\",\"TGS\",\"LogOff\",\"LogOff\",\"AuthMap\"],[\"LogOn\",\"LogOff\",\"LogOn\",\"LogOff\",\"LogOn\",...,\"LogOn\",\"LogOn\",\"LogOn\",\"LogOn\",\"LogOn\"],...,[\"LogOff\",\"TGT\",\"TGS\",\"LogOff\",\"LogOn\",...,\"LogOff\",\"LogOn\",\"LogOn\",\"LogOn\",\"LogOff\"],[\"LogOff\",\"LogOn\",\"LogOn\",\"LogOn\",\"LogOn\",...,\"TGS\",\"TGT\",\"LogOn\",\"TGT\",\"TGS\"]]\n",
      "Success: [[\"Success\",\"Success\",\"Success\",\"Success\",\"Success\",...,\"Success\",\"Success\",\"Success\",\"Success\",\"Success\"],[\"Success\",\"Success\",\"Success\",\"Success\",\"Success\",...,\"Success\",\"Success\",\"Success\",\"Success\",\"Success\"],...,[\"Success\",\"Success\",\"Success\",\"Success\",\"Success\",...,\"Success\",\"Success\",\"Success\",\"Success\",\"Success\"],[\"Success\",\"Success\",\"Success\",\"Success\",\"Success\",...,\"Success\",\"Success\",\"Success\",\"Success\",\"Success\"]]\n",
      "1: [[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1],...,[29,29,29,29,29,...,29,29,29,29,29],[29,29,29,29,29,...,29,29,29,29,29]]\n"
     ]
    }
   ],
   "source": [
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef056a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function column:\n",
      "\n",
      "column(...) method of pyarrow.lib.Table instance\n",
      "    Table.column(self, i)\n",
      "    \n",
      "    Select a column by its column name, or numeric index.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    i : int or string\n",
      "        The index or name of the column to retrieve.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ChunkedArray\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pyarrow as pa\n",
      "    >>> import pandas as pd\n",
      "    >>> df = pd.DataFrame({'n_legs': [2, 4, 5, 100],\n",
      "    ...                    'animals': [\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"]})\n",
      "    >>> table = pa.Table.from_pandas(df)\n",
      "    \n",
      "    Select a column by numeric index:\n",
      "    \n",
      "    >>> table.column(0)\n",
      "    <pyarrow.lib.ChunkedArray object at ...>\n",
      "    [\n",
      "      [\n",
      "        2,\n",
      "        4,\n",
      "        5,\n",
      "        100\n",
      "      ]\n",
      "    ]\n",
      "    \n",
      "    Select a column by its name:\n",
      "    \n",
      "    >>> table.column(\"animals\")\n",
      "    <pyarrow.lib.ChunkedArray object at ...>\n",
      "    [\n",
      "      [\n",
      "        \"Flamingo\",\n",
      "        \"Horse\",\n",
      "        \"Brittle stars\",\n",
      "        \"Centipede\"\n",
      "      ]\n",
      "    ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file.column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3a28471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function set_column:\n",
      "\n",
      "set_column(...) method of pyarrow.lib.Table instance\n",
      "    Table.set_column(self, int i, field_, column)\n",
      "    \n",
      "    Replace column in Table at position.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    i : int\n",
      "        Index to place the column at.\n",
      "    field_ : str or Field\n",
      "        If a string is passed then the type is deduced from the column\n",
      "        data.\n",
      "    column : Array, list of Array, or values coercible to arrays\n",
      "        Column data.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Table\n",
      "        New table with the passed column set.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pyarrow as pa\n",
      "    >>> import pandas as pd\n",
      "    >>> df = pd.DataFrame({'n_legs': [2, 4, 5, 100],\n",
      "    ...                    'animals': [\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"]})\n",
      "    >>> table = pa.Table.from_pandas(df)\n",
      "    \n",
      "    Replace a column:\n",
      "    \n",
      "    >>> year = [2021, 2022, 2019, 2021]\n",
      "    >>> table.set_column(1,'year', [year])\n",
      "    pyarrow.Table\n",
      "    n_legs: int64\n",
      "    year: int64\n",
      "    ----\n",
      "    n_legs: [[2,4,5,100]]\n",
      "    year: [[2021,2022,2019,2021]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file.set_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b58abbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Schema object:\n",
      "\n",
      "class Schema(_Weakrefable)\n",
      " |  Schema()\n",
      " |  \n",
      " |  A named collection of types a.k.a schema. A schema defines the\n",
      " |  column names and types in a record batch or table data structure.\n",
      " |  They also contain metadata about the columns. For example, schemas \n",
      " |  converted from Pandas contain metadata about their original Pandas \n",
      " |  types so they can be converted back to the same types.\n",
      " |  \n",
      " |  Warnings\n",
      " |  --------\n",
      " |  Do not call this class's constructor directly. Instead use\n",
      " |  :func:`pyarrow.schema` factory function which makes a new Arrow\n",
      " |  Schema object.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Create a new Arrow Schema object:\n",
      " |  \n",
      " |  >>> import pyarrow as pa\n",
      " |  >>> pa.schema([\n",
      " |  ...     ('some_int', pa.int32()),\n",
      " |  ...     ('some_string', pa.string())\n",
      " |  ... ])\n",
      " |  some_int: int32\n",
      " |  some_string: string\n",
      " |  \n",
      " |  Create Arrow Schema with metadata:\n",
      " |  \n",
      " |  >>> pa.schema([\n",
      " |  ...     pa.field('n_legs', pa.int64()),\n",
      " |  ...     pa.field('animals', pa.string())],\n",
      " |  ...     metadata={\"n_legs\": \"Number of legs per animal\"})\n",
      " |  n_legs: int64\n",
      " |  animals: string\n",
      " |  -- schema metadata --\n",
      " |  n_legs: 'Number of legs per animal'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Schema\n",
      " |      _Weakrefable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Schema.__reduce__(self)\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      Schema.__sizeof__(self)\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_metadata(...)\n",
      " |      Schema.add_metadata(self, metadata)\n",
      " |      \n",
      " |      DEPRECATED\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      metadata : dict\n",
      " |          Keys and values must be string-like / coercible to bytes\n",
      " |  \n",
      " |  append(...)\n",
      " |      Schema.append(self, Field field)\n",
      " |      \n",
      " |      Append a field at the end of the schema.\n",
      " |      \n",
      " |      In contrast to Python's ``list.append()`` it does return a new\n",
      " |      object, leaving the original Schema unmodified.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      field : Field\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      schema: Schema\n",
      " |          New object with appended field.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Append a field 'extra' at the end of the schema:\n",
      " |      \n",
      " |      >>> schema_new = schema.append(pa.field('extra', pa.bool_()))\n",
      " |      >>> schema_new\n",
      " |      n_legs: int64\n",
      " |      animals: string\n",
      " |      extra: bool\n",
      " |      \n",
      " |      Original schema is unmodified:\n",
      " |      \n",
      " |      >>> schema\n",
      " |      n_legs: int64\n",
      " |      animals: string\n",
      " |  \n",
      " |  empty_table(...)\n",
      " |      Schema.empty_table(self)\n",
      " |      \n",
      " |      Provide an empty table according to the schema.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      table: pyarrow.Table\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Create an empty table with schema's fields:\n",
      " |      \n",
      " |      >>> schema.empty_table()\n",
      " |      pyarrow.Table\n",
      " |      n_legs: int64\n",
      " |      animals: string\n",
      " |      ----\n",
      " |      n_legs: [[]]\n",
      " |      animals: [[]]\n",
      " |  \n",
      " |  equals(...)\n",
      " |      Schema.equals(self, Schema other, bool check_metadata=False)\n",
      " |      \n",
      " |      Test if this schema is equal to the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other :  pyarrow.Schema\n",
      " |      check_metadata : bool, default False\n",
      " |          Key/value metadata must be equal too\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_equal : bool\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema1 = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())],\n",
      " |      ...     metadata={\"n_legs\": \"Number of legs per animal\"})\n",
      " |      >>> schema2 = pa.schema([\n",
      " |      ...     ('some_int', pa.int32()),\n",
      " |      ...     ('some_string', pa.string())\n",
      " |      ... ])\n",
      " |      \n",
      " |      Test two equal schemas:\n",
      " |      \n",
      " |      >>> schema1.equals(schema1)\n",
      " |      True\n",
      " |      \n",
      " |      Test two unequal schemas:\n",
      " |      \n",
      " |      >>> schema1.equals(schema2)\n",
      " |      False\n",
      " |  \n",
      " |  field(...)\n",
      " |      Schema.field(self, i)\n",
      " |      \n",
      " |      Select a field by its column name or numeric index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i : int or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pyarrow.Field\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Select the second field:\n",
      " |      \n",
      " |      >>> schema.field(1)\n",
      " |      pyarrow.Field<animals: string>\n",
      " |      \n",
      " |      Select the field of the column named 'n_legs':\n",
      " |      \n",
      " |      >>> schema.field('n_legs')\n",
      " |      pyarrow.Field<n_legs: int64>\n",
      " |  \n",
      " |  field_by_name(...)\n",
      " |      Schema.field_by_name(self, name)\n",
      " |      \n",
      " |      DEPRECATED\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      field: pyarrow.Field\n",
      " |  \n",
      " |  get_all_field_indices(...)\n",
      " |      Schema.get_all_field_indices(self, name)\n",
      " |      \n",
      " |      Return sorted list of indices for the fields with the given name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          The name of the field to look up.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : List[int]\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string()),\n",
      " |      ...     pa.field('animals', pa.bool_())])\n",
      " |      \n",
      " |      Get the indexes of the fields named 'animals':\n",
      " |      \n",
      " |      >>> schema.get_all_field_indices(\"animals\")\n",
      " |      [1, 2]\n",
      " |  \n",
      " |  get_field_index(...)\n",
      " |      Schema.get_field_index(self, name)\n",
      " |      \n",
      " |      Return index of the unique field with the given name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          The name of the field to look up.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      index : int\n",
      " |          The index of the field with the given name; -1 if the\n",
      " |          name isn't found or there are several fields with the given\n",
      " |          name.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Get the index of the field named 'animals':\n",
      " |      \n",
      " |      >>> schema.get_field_index(\"animals\")\n",
      " |      1\n",
      " |      \n",
      " |      Index in case of several fields with the given name:\n",
      " |      \n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string()),\n",
      " |      ...     pa.field('animals', pa.bool_())],\n",
      " |      ...     metadata={\"n_legs\": \"Number of legs per animal\"})\n",
      " |      >>> schema.get_field_index(\"animals\")\n",
      " |      -1\n",
      " |  \n",
      " |  insert(...)\n",
      " |      Schema.insert(self, int i, Field field)\n",
      " |      \n",
      " |      Add a field at position i to the schema.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i : int\n",
      " |      field : Field\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      schema: Schema\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Insert a new field on the second position:\n",
      " |      \n",
      " |      >>> schema.insert(1, pa.field('extra', pa.bool_()))\n",
      " |      n_legs: int64\n",
      " |      extra: bool\n",
      " |      animals: string\n",
      " |  \n",
      " |  remove(...)\n",
      " |      Schema.remove(self, int i)\n",
      " |      \n",
      " |      Remove the field at index i from the schema.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      schema: Schema\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Remove the second field of the schema:\n",
      " |      \n",
      " |      >>> schema.remove(1)\n",
      " |      n_legs: int64\n",
      " |  \n",
      " |  remove_metadata(...)\n",
      " |      Schema.remove_metadata(self)\n",
      " |      \n",
      " |      Create new schema without metadata, if any\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      schema : pyarrow.Schema\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())],\n",
      " |      ...     metadata={\"n_legs\": \"Number of legs per animal\"})\n",
      " |      >>> schema\n",
      " |      n_legs: int64\n",
      " |      animals: string\n",
      " |      -- schema metadata --\n",
      " |      n_legs: 'Number of legs per animal'\n",
      " |      \n",
      " |      Create a new schema with removing the metadata from the original:\n",
      " |      \n",
      " |      >>> schema.remove_metadata()\n",
      " |      n_legs: int64\n",
      " |      animals: string\n",
      " |  \n",
      " |  serialize(...)\n",
      " |      Schema.serialize(self, memory_pool=None)\n",
      " |      \n",
      " |      Write Schema to Buffer as encapsulated IPC message\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memory_pool : MemoryPool, default None\n",
      " |          Uses default memory pool if not specified\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      serialized : Buffer\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Write schema to Buffer:\n",
      " |      \n",
      " |      >>> schema.serialize()\n",
      " |      <pyarrow.Buffer address=0x... size=... is_cpu=True is_mutable=True>\n",
      " |  \n",
      " |  set(...)\n",
      " |      Schema.set(self, int i, Field field)\n",
      " |      \n",
      " |      Replace a field at position i in the schema.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i : int\n",
      " |      field : Field\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      schema: Schema\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Replace the second field of the schema with a new field 'extra':\n",
      " |      \n",
      " |      >>> schema.set(1, pa.field('replaced', pa.bool_()))\n",
      " |      n_legs: int64\n",
      " |      replaced: bool\n",
      " |  \n",
      " |  to_string(...)\n",
      " |      Schema.to_string(self, truncate_metadata=True, show_field_metadata=True, show_schema_metadata=True)\n",
      " |      \n",
      " |      Return human-readable representation of Schema\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      truncate_metadata : boolean, default True\n",
      " |          Limit metadata key/value display to a single line of ~80 characters\n",
      " |          or less\n",
      " |      show_field_metadata : boolean, default True\n",
      " |          Display Field-level KeyValueMetadata\n",
      " |      show_schema_metadata : boolean, default True\n",
      " |          Display Schema-level KeyValueMetadata\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str : the formatted output\n",
      " |  \n",
      " |  with_metadata(...)\n",
      " |      Schema.with_metadata(self, metadata)\n",
      " |      \n",
      " |      Add metadata as dict of string keys and values to Schema\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      metadata : dict\n",
      " |          Keys and values must be string-like / coercible to bytes\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      schema : pyarrow.Schema\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Add metadata to existing schema field:\n",
      " |      \n",
      " |      >>> schema.with_metadata({\"n_legs\": \"Number of legs per animal\"})\n",
      " |      n_legs: int64\n",
      " |      animals: string\n",
      " |      -- schema metadata --\n",
      " |      n_legs: 'Number of legs per animal'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_pandas(...) from builtins.type\n",
      " |      Schema.from_pandas(type cls, df, preserve_index=None)\n",
      " |      \n",
      " |      Returns implied schema from dataframe\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      df : pandas.DataFrame\n",
      " |      preserve_index : bool, default True\n",
      " |          Whether to store the index as an additional column (or columns, for\n",
      " |          MultiIndex) in the resulting `Table`.\n",
      " |          The default of None will store the index as a column, except for\n",
      " |          RangeIndex which is stored as metadata only. Use\n",
      " |          ``preserve_index=True`` to force it to be stored as a column.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pyarrow.Schema\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'int': [1, 2],\n",
      " |      ...     'str': ['a', 'b']\n",
      " |      ... })\n",
      " |      \n",
      " |      Create an Arrow Schema from the schema of a pandas dataframe:\n",
      " |      \n",
      " |      >>> pa.Schema.from_pandas(df)\n",
      " |      int: int64\n",
      " |      str: string\n",
      " |      -- schema metadata --\n",
      " |      pandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, ...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  metadata\n",
      " |      The schema's metadata.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      metadata: dict\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())],\n",
      " |      ...     metadata={\"n_legs\": \"Number of legs per animal\"})\n",
      " |      \n",
      " |      Get the metadata of the schema's fields:\n",
      " |      \n",
      " |      >>> schema.metadata\n",
      " |      {b'n_legs': b'Number of legs per animal'}\n",
      " |  \n",
      " |  names\n",
      " |      The schema's field names.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Get the names of the schema's fields:\n",
      " |      \n",
      " |      >>> schema.names\n",
      " |      ['n_legs', 'animals']\n",
      " |  \n",
      " |  pandas_metadata\n",
      " |      Return deserialized-from-JSON pandas metadata field (if it exists)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> import pandas as pd\n",
      " |      >>> df = pd.DataFrame({'n_legs': [2, 4, 5, 100],\n",
      " |      ...                    'animals': [\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"]})\n",
      " |      >>> schema = pa.Table.from_pandas(df).schema\n",
      " |      \n",
      " |      Select pandas metadata field from Arrow Schema:\n",
      " |      \n",
      " |      >>> schema.pandas_metadata\n",
      " |      {'index_columns': [{'kind': 'range', 'name': None, 'start': 0, 'stop': 4, 'step': 1}], ...\n",
      " |  \n",
      " |  types\n",
      " |      The schema's field types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of DataType\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pyarrow as pa\n",
      " |      >>> schema = pa.schema([\n",
      " |      ...     pa.field('n_legs', pa.int64()),\n",
      " |      ...     pa.field('animals', pa.string())])\n",
      " |      \n",
      " |      Get the types of the schema's fields:\n",
      " |      \n",
      " |      >>> schema.types\n",
      " |      [DataType(int64), DataType(string)]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03989c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time: int64\n",
       "source user@domain: string\n",
       "destination user@domain: string\n",
       "source computer: string\n",
       "destination computer: string\n",
       "authentication type: string\n",
       "logon type: string\n",
       "authentication orientation: string\n",
       "success/failure: string\n",
       "day: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "pa.schema([ \n",
    "    ('time', pa.int64()),\n",
    "    ('source user@domain', pa.string()),\n",
    "    ('destination user@domain', pa.string()),\n",
    "    ('source computer', pa.string()),\n",
    "    ('destination computer', pa.string()),\n",
    "    ('authentication type', pa.string()),\n",
    "    ('logon type', pa.string()),\n",
    "    ('authentication orientation', pa.string()),\n",
    "    ('success/failure', pa.string()),\n",
    "    ('day', pa.int64()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "075891fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "498d2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_schema =  pa.schema([ \n",
    "    ('time', pa.int64()),\n",
    "    ('source user@domain', pa.string()),\n",
    "    ('destination user@domain', pa.string()),\n",
    "    ('source computer', pa.string()),\n",
    "    ('destination computer', pa.string()),\n",
    "    ('authentication type', pa.string()),\n",
    "    ('logon type', pa.string()),\n",
    "    ('authentication orientation', pa.string()),\n",
    "    ('success/failure', pa.string()),\n",
    "    ('day', pa.int64()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f2cff3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target schema's field names are not matching the table's field names: ['1', 'ANONYMOUS LOGON@C586', 'ANONYMOUS LOGON@C586', 'C1250', 'C586', 'NTLM', 'Network', 'LogOn', 'Success', '1'], ['time', 'source user@domain', 'destination user@domain', 'source computer', 'destination computer', 'authentication type', 'logon type', 'authentication orientation', 'success/failure', 'day']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file2 \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43myour_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyarrow/table.pxi:3481\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.cast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target schema's field names are not matching the table's field names: ['1', 'ANONYMOUS LOGON@C586', 'ANONYMOUS LOGON@C586', 'C1250', 'C586', 'NTLM', 'Network', 'LogOn', 'Success', '1'], ['time', 'source user@domain', 'destination user@domain', 'source computer', 'destination computer', 'authentication type', 'logon type', 'authentication orientation', 'success/failure', 'day']"
     ]
    }
   ],
   "source": [
    "file2 = file.cast(your_schema, safe=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2046ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function cast:\n",
      "\n",
      "cast(...) method of pyarrow.lib.Table instance\n",
      "    Table.cast(self, Schema target_schema, safe=None, options=None)\n",
      "    \n",
      "    Cast table values to another schema.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    target_schema : Schema\n",
      "        Schema to cast to, the names and order of fields must match.\n",
      "    safe : bool, default True\n",
      "        Check for overflows or other unsafe conversions.\n",
      "    options : CastOptions, default None\n",
      "        Additional checks pass by CastOptions\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Table\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pyarrow as pa\n",
      "    >>> import pandas as pd\n",
      "    >>> df = pd.DataFrame({'n_legs': [2, 4, 5, 100],\n",
      "    ...                    'animals': [\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"]})\n",
      "    >>> table = pa.Table.from_pandas(df)\n",
      "    >>> table.schema\n",
      "    n_legs: int64\n",
      "    animals: string\n",
      "    -- schema metadata --\n",
      "    pandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, ...\n",
      "    \n",
      "    Define new schema and cast table values:\n",
      "    \n",
      "    >>> my_schema = pa.schema([\n",
      "    ...     pa.field('n_legs', pa.duration('s')),\n",
      "    ...     pa.field('animals', pa.string())]\n",
      "    ...     )\n",
      "    >>> table.cast(target_schema=my_schema)\n",
      "    pyarrow.Table\n",
      "    n_legs: duration[s]\n",
      "    animals: string\n",
      "    ----\n",
      "    n_legs: [[2,4,5,100]]\n",
      "    animals: [[\"Flamingo\",\"Horse\",\"Brittle stars\",\"Centipede\"]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file.cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c1f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
